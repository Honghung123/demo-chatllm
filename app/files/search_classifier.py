from typing import List, Dict, Optional, Tuple
import os
import json
from pathlib import Path
from app.files.file_loader import load_file
from app.files.file_classifier import classify_file
from app.mcp.sender import send_classified_files
from app.llm.prompt_templates import SEARCH_PROMPT, COT_PROMPT, RLHF_CONFIRM_PROMPT
from app.search.retriever import get_retriever

# Th∆∞ m·ª•c l∆∞u tr·ªØ ph·∫£n h·ªìi RLHF
RLHF_FEEDBACK_DIR = "data/rlhf_feedback"
RLHF_FEEDBACK_FILE = os.path.join(RLHF_FEEDBACK_DIR, "user_feedback.json")

# T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a t·ªìn t·∫°i
os.makedirs(RLHF_FEEDBACK_DIR, exist_ok=True)

def load_rlhf_feedback() -> Dict[str, Dict[str, str]]:
    """
    T·∫£i d·ªØ li·ªáu ph·∫£n h·ªìi t·ª´ ng∆∞·ªùi d√πng
    
    Returns:
        Dict v·ªõi key l√† file_path v√† value l√† dict ch·ª©a label ƒë∆∞·ª£c ng∆∞·ªùi d√πng x√°c nh·∫≠n
    """
    if not os.path.exists(RLHF_FEEDBACK_FILE):
        return {}
    
    try:
        with open(RLHF_FEEDBACK_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f"‚ùå L·ªói khi t·∫£i d·ªØ li·ªáu RLHF: {str(e)}")
        return {}

def save_rlhf_feedback(feedback_data: Dict[str, Dict[str, str]]):
    """
    L∆∞u d·ªØ li·ªáu ph·∫£n h·ªìi t·ª´ ng∆∞·ªùi d√πng
    
    Args:
        feedback_data: Dict v·ªõi key l√† file_path v√† value l√† dict ch·ª©a label ƒë∆∞·ª£c ng∆∞·ªùi d√πng x√°c nh·∫≠n
    """
    try:
        with open(RLHF_FEEDBACK_FILE, 'w', encoding='utf-8') as f:
            json.dump(feedback_data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"‚ùå L·ªói khi l∆∞u d·ªØ li·ªáu RLHF: {str(e)}")

def search_files(query: str, directory: str = "data/documents") -> List[str]:
    """
    T√¨m ki·∫øm c√°c file trong th∆∞ m·ª•c d·ª±a tr√™n c√¢u query.
    
    Args:
        query: C√¢u truy v·∫•n t√¨m ki·∫øm
        directory: Th∆∞ m·ª•c ch·ª©a file c·∫ßn t√¨m
        
    Returns:
        Danh s√°ch ƒë∆∞·ªùng d·∫´n c√°c file t√¨m th·∫•y
    """
    # Ki·ªÉm tra th∆∞ m·ª•c t·ªìn t·∫°i
    if not os.path.exists(directory):
        print(f"‚ùå Th∆∞ m·ª•c {directory} kh√¥ng t·ªìn t·∫°i")
        return []
        
    # S·ª≠ d·ª•ng vector store ƒë·ªÉ t√¨m ki·∫øm hi·ªáu qu·∫£
    print(f"üîç ƒêang t√¨m ki·∫øm files v·ªõi query: '{query}'")
    
    try:
        # Ki·ªÉm tra v√† x·ª≠ l√Ω t√¨m ki·∫øm ƒë∆°n gi·∫£n tr∆∞·ªõc
        # N·∫øu query tr·ª±c ti·∫øp l√† t√™n file ho·∫∑c t·ª´ kh√≥a r√µ r√†ng, t√¨m nhanh h∆°n
        # keyword_matches = []
        all_files = [os.path.join(directory, f) for f in os.listdir(directory) 
                     if os.path.isfile(os.path.join(directory, f)) and not f.startswith('.')]
                     
        # Ki·ªÉm tra t·ª´ kh√≥a tr·ª±c ti·∫øp trong t√™n file
        # for file_path in all_files:
        #     file_name = os.path.basename(file_path).lower()
        #     query_parts = query.lower().split()
            
        #     # N·∫øu c√≥ b·∫•t k·ª≥ t·ª´ kh√≥a n√†o trong t√™n file
        #     if any(part in file_name for part in query_parts if len(part) > 2):
        #         keyword_matches.append(file_path) 
        
        # N·∫øu t√¨m ƒë∆∞·ª£c qua t·ª´ kh√≥a, ∆∞u ti√™n tr·∫£ v·ªÅ
        # if keyword_matches: 
        #     return keyword_matches
            
        # N·∫øu kh√¥ng t√¨m ƒë∆∞·ª£c qua t·ª´ kh√≥a, s·ª≠ d·ª•ng vector search
        print(f"üîç ƒêang t√¨m ki·∫øm vector v·ªõi query: '{query}'")
        retriever = get_retriever(directory)
        
        # ƒê·∫£m b·∫£o files ƒë∆∞·ª£c index
        if not retriever.index_files():
            print(f"‚ö†Ô∏è Kh√¥ng th·ªÉ ƒë√°nh ch·ªâ m·ª•c file trong th∆∞ m·ª•c {directory}")
        
        # L·∫•y danh s√°ch file li√™n quan
        vector_results = retriever.get_relevant_files(query)
        
        if vector_results:
            print(f"‚úì Vector search t√¨m th·∫•y {len(vector_results)} file")
            return vector_results
            
        # N·∫øu v·∫´n kh√¥ng c√≥ k·∫øt qu·∫£, d√πng fallback
        print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£ t·ª´ vector search, s·ª≠ d·ª•ng fallback")
            
        # Fallback: S·ª≠ d·ª•ng ph∆∞∆°ng ph√°p t√¨m ki·∫øm tr·ª±c ti·∫øp
        from app.llm.chat_engine import chat_llm  # Import here to avoid circular dependency
        
        file_paths = []
        file_summaries = []
        
        for file_path in all_files:
            content = load_file(file_path)
            if content and isinstance(content, str) and content.strip():
                # Gi·ªõi h·∫°n n·ªôi dung ƒë·ªÉ ti·∫øt ki·ªám token
                file_summaries.append(f"File: {os.path.basename(file_path)}\nN·ªôi dung: {content[:2000]}...")
                file_paths.append(file_path)
        
        if not file_paths:
            return []
        
        # D√πng LLM ƒë·ªÉ t√¨m c√°c file li√™n quan ƒë·∫øn c√¢u h·ªèi
        prompt = SEARCH_PROMPT.format(query=query, file_summaries="\n\n".join(file_summaries))
        response = chat_llm(prompt, streaming=False)
        print(f"ü§ñ LLM response: {response}")
        
        # X·ª≠ l√Ω k·∫øt qu·∫£ tr·∫£ v·ªÅ t·ª´ LLM ƒë·ªÉ l·∫•y danh s√°ch file li√™n quan
        relevant_files = []
        for line in response.split("\n"):
            line = line.strip()
            if not line:
                continue
            # T√¨m file trong danh s√°ch ban ƒë·∫ßu
            for file_path in file_paths:
                file_name = os.path.basename(file_path)
                if file_name.lower() in line.lower():
                    relevant_files.append(file_path)
                    print(f"‚úì T√¨m th·∫•y file qua LLM: {file_name}")
                    break
        
        return relevant_files
    except Exception as e:
        print(f"‚ùå L·ªói khi t√¨m ki·∫øm files: {str(e)}")
        return []

def get_file_classification(file_path: str, labels: List[str], method: str = "llm") -> str:
    """
    Ph√¢n lo·∫°i file v·ªõi t√≠ch h·ª£p RLHF - ki·ªÉm tra ph·∫£n h·ªìi ng∆∞·ªùi d√πng tr∆∞·ªõc khi ph√¢n lo·∫°i
    
    Args:
        file_path: ƒê∆∞·ªùng d·∫´n file
        labels: Danh s√°ch nh√£n
        method: Ph∆∞∆°ng ph√°p ph√¢n lo·∫°i
        
    Returns:
        Nh√£n ph√¢n lo·∫°i
    """
    # Ki·ªÉm tra xem ƒë√£ c√≥ ph·∫£n h·ªìi t·ª´ ng∆∞·ªùi d√πng ch∆∞a
    rlhf_data = load_rlhf_feedback()
    if file_path in rlhf_data and "user_label" in rlhf_data[file_path]:
        user_label = rlhf_data[file_path]["user_label"]
        # Ki·ªÉm tra xem nh√£n ng∆∞·ªùi d√πng c√≥ trong danh s√°ch nh√£n kh√¥ng
        if user_label in labels:
            return user_label
    print(f"Ch∆∞a c√≥ ph·∫£n h·ªìi t·ª´ ng∆∞·ªùi d√πng cho {file_path}. LLM s·∫Ω th·ª±c hi·ªán ph√¢n lo·∫°i.")
    # N·∫øu kh√¥ng c√≥ ph·∫£n h·ªìi, th·ª±c hi·ªán ph√¢n lo·∫°i th√¥ng th∆∞·ªùng
    return classify_file(file_path, labels, method=method)

def format_search_results(results: List[Dict], explanation: str) -> str:
    """
    Format k·∫øt qu·∫£ t√¨m ki·∫øm ƒë·ªÉ hi·ªÉn th·ªã cho ng∆∞·ªùi d√πng
    
    Args:
        results: Danh s√°ch k·∫øt qu·∫£ t√¨m ki·∫øm
        explanation: Gi·∫£i th√≠ch CoT
        
    Returns:
        Chu·ªói k·∫øt qu·∫£ ƒë√£ ƒë∆∞·ª£c format
    """
    if not results:
        return "‚ùå Kh√¥ng t√¨m th·∫•y file n√†o ph√π h·ª£p."
    
    # Kh·ªüi t·∫°o output tr∆∞·ªõc khi s·ª≠ d·ª•ng
    output = "üîç K·∫æT QU·∫¢ T√åM KI·∫æM\n"
    output += "=" * 40 + "\n\n"
    
    # Ph√¢n lo·∫°i theo nh√≥m
    group_a = [r for r in results if r.get("label") == "A"]
    group_b = [r for r in results if r.get("label") == "B"]
    others = [r for r in results if r.get("label") not in ["A", "B"]]
    
    if group_a:
        output += "‚úÖ ƒê√∫ng n·ªôi dung c·∫ßn t√¨m (Nh√≥m A):\n"
        for item in group_a:
            output += f"  ‚Ä¢ {item['file_name']}\n"
        output += "\n"
    
    if group_b:
        output += "‚ÑπÔ∏è C√≥ n·ªôi dung li√™n quan (Nh√≥m B):\n"
        for item in group_b:
            output += f"  ‚Ä¢ {item['file_name']}\n"
        output += "\n"
    
    if others:
        output += "‚ö†Ô∏è C√°c file kh√°c:\n"
        for item in others:
            output += f"  ‚Ä¢ {item['file_name']} (Nh√≥m {item.get('label', '?')})\n"
        output += "\n"
    
    # Gi·∫£i th√≠ch CoT
    output += "\n\nüìù PH√ÇN T√çCH QUY TR√åNH\n"
    output += "=" * 40 + "\n"
    output += explanation
    
    # Th√™m ph·∫ßn RLHF
    output += "\n\nüí¨ PH·∫¢N H·ªíI\n"
    output += "=" * 40 + "\n"
    output += "ƒê·ªÉ ƒëi·ªÅu ch·ªânh ph√¢n lo·∫°i, h√£y nh·∫≠p: 'ƒëi·ªÅu ch·ªânh [t√™n file] [nh√£n m·ªõi]'\n"
    output += "V√≠ d·ª•: ƒëi·ªÅu ch·ªânh git-cheat-sheet.pdf B\n"
    
    return output

def handle_search_and_classify(query: str, directory: str = "data/documents", 
                      labels: List[str] = ["A", "B"]) -> Tuple[List[Dict], str]:
    """
    T√¨m ki·∫øm v√† ph√¢n lo·∫°i c√°c file d·ª±a tr√™n c√¢u query.
    Tr·∫£ v·ªÅ nh√≥m A n·∫øu ƒë√∫ng n·ªôi dung c·∫ßn t√¨m, nh√≥m B n·∫øu c√≥ n·ªôi dung li√™n quan.
    
    Args:
        query: C√¢u truy v·∫•n t√¨m ki·∫øm
        directory: Th∆∞ m·ª•c ch·ª©a file c·∫ßn t√¨m
        labels: Danh s√°ch nh√£n ph√¢n lo·∫°i
        
    Returns:
        Tuple (danh s√°ch th√¥ng tin c√°c file t√¨m th·∫•y, chu·ªói CoT gi·∫£i th√≠ch)
    """
    # Import here to avoid circular dependency
    from app.llm.chat_engine import chat_llm
    
    # T√¨m c√°c file li√™n quan
    relevant_files = search_files(query, directory)
    
    if not relevant_files:
        return [], f"Kh√¥ng t√¨m th·∫•y file n√†o li√™n quan ƒë·∫øn: '{query}'"
    else:
        print(f"üîç T√¨m th·∫•y {len(relevant_files)} file li√™n quan ƒë·∫øn: '{query}' - {relevant_files}")
    
    # Ph√¢n lo·∫°i c√°c file t√¨m th·∫•y
    file_summaries = []
    classified_results = []
    
    for file_path in relevant_files:
        content = load_file(file_path)
        file_name = os.path.basename(file_path)
        
        if not content:
            continue
            
        # Ph√¢n lo·∫°i n·ªôi dung s·ª≠ d·ª•ng RLHF
        label = get_file_classification(file_path, labels, method="llm")
        print(f"Ph√¢n lo·∫°i file: {file_name} - {label}")
        
        # T·∫°o t√≥m t·∫Øt ƒë·ªÉ hi·ªÉn th·ªã v√† CoT
        summary = content[:3000] + "..." if len(content) > 3000 else content
        file_summaries.append(f"File: {file_name}\nN·ªôi dung: {summary}\nPh√¢n lo·∫°i: {label}")
        
        classified_results.append({
            "file_path": file_path,
            "file_name": file_name,
            "label": label,
            "content_preview": summary
        })
    
    # T·∫°o Chain of Thought gi·∫£i th√≠ch
    if classified_results:
        cot_prompt = COT_PROMPT.format(
            query=query, 
            file_summaries="\n\n".join(file_summaries)
        )
        cot_explanation = chat_llm(cot_prompt, streaming=False)
    else:
        cot_explanation = f"ƒê√£ t√¨m th·∫•y {len(relevant_files)} file nh∆∞ng kh√¥ng ph√¢n lo·∫°i ƒë∆∞·ª£c."
    
    # G·ª≠i metadata qua MCP
    send_classified_files(
        file_paths=[item["file_path"] for item in classified_results],
        labels=labels,
        classification_method="llm",
        include_summary=False
    )
    
    return format_search_results(classified_results, cot_explanation)

def process_rlhf_feedback(user_input: str) -> str:
    """
    X·ª≠ l√Ω ph·∫£n h·ªìi t·ª´ ng∆∞·ªùi d√πng v·ªÅ ph√¢n lo·∫°i file (RLHF)
    
    Args:
        user_input: Ph·∫£n h·ªìi c·ªßa ng∆∞·ªùi d√πng, ƒë·ªãnh d·∫°ng "ƒëi·ªÅu ch·ªânh [t√™n file] [nh√£n m·ªõi]"
        
    Returns:
        Th√¥ng b√°o k·∫øt qu·∫£
    """
    # X·ª≠ l√Ω c√∫ ph√°p: ƒëi·ªÅu ch·ªânh [t√™n file] [nh√£n m·ªõi]
    parts = user_input.strip().split(' ')
    if len(parts) < 3:
        return "‚ùå C√∫ ph√°p kh√¥ng ƒë√∫ng. Vui l√≤ng s·ª≠ d·ª•ng: 'ƒëi·ªÅu ch·ªânh [t√™n file] [nh√£n m·ªõi]'"
    
    file_name = parts[1]
    new_label = parts[2].upper()
    
    # T√¨m file trong th∆∞ m·ª•c documents
    doc_dir = "data/documents"
    file_path = None
    for root, _, files in os.walk(doc_dir):
        for f in files:
            if f.lower() == file_name.lower():
                file_path = os.path.join(root, f)
                break
    
    if not file_path:
        return f"‚ùå Kh√¥ng t√¨m th·∫•y file: {file_name}"
    
    # L∆∞u ph·∫£n h·ªìi v√†o RLHF store
    rlhf_data = load_rlhf_feedback()
    rlhf_data[file_path] = {
        "file_name": file_name,
        "user_label": new_label,
        "timestamp": str(Path(file_path).stat().st_mtime)
    }
    save_rlhf_feedback(rlhf_data)
    
    # G·ª≠i metadata c·∫≠p nh·∫≠t
    try:
        send_classified_files(
            file_paths=[file_path],
            labels=["A", "B", new_label],
            classification_method="rlhf",
            include_summary=False
        )
        return f"‚úÖ ƒê√£ c·∫≠p nh·∫≠t nh√£n c·ªßa file {file_name} th√†nh {new_label}"
    except Exception as e:
        return f"‚ö†Ô∏è ƒê√£ l∆∞u ph·∫£n h·ªìi nh∆∞ng g·∫∑p l·ªói khi g·ª≠i metadata: {str(e)}" 